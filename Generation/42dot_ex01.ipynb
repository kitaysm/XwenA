{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMRIawBahrYrt9kEHK/PEE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4csqn26BBbR","executionInfo":{"status":"ok","timestamp":1708677063857,"user_tz":-540,"elapsed":6109,"user":{"displayName":"Geass J","userId":"06622059162331348427"}},"outputId":"36ee4d98-8b4b-44a0-b5da-81b27889594d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["pip install peft"],"metadata":{"id":"esknLFmdCOi5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install trl"],"metadata":{"id":"E_CZskc-CPnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os  # os 모듈 운영체제와 상호 작용할 수 있는 기능을 제공\n","import torch # PyTorch 라이브러리로, 주로 딥러닝과 머신러닝 모델을 구축, 학습, 테스트하는 데 사용\n","# from datasets import load_dataset  # 데이터셋을 쉽게 불러오고 처리할 수 있는 기능을 제공\n","from transformers import (\n","    AutoModelForCausalLM, # 인과적 언어 추론(예: GPT)을 위한 모델을 자동으로 불러오는 클래스\n","    AutoTokenizer, # 입력 문장을 토큰 단위로 자동으로 잘라주는 역할\n","    BitsAndBytesConfig, # 모델 구성\n","    HfArgumentParser,  # 파라미터 파싱\n","    TrainingArguments,  # 훈련 설정\n","    pipeline,  # 파이프라인 설정\n","    logging,  #로깅을 위한 클래스\n",")\n","\n","# 모델 튜닝을 위한 라이브러리\n","from peft import LoraConfig, PeftModel\n","from trl import SFTTrainer"],"metadata":{"id":"M1FMFF3QAA6X","executionInfo":{"status":"ok","timestamp":1708677111152,"user_tz":-540,"elapsed":20643,"user":{"displayName":"Geass J","userId":"06622059162331348427"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Hugging Face 허브에서 훈련하고자 하는 모델을 가져와서 이름 지정\n","model_name = '42dot/42dot_LLM-SFT-1.3B'\n","\n","# model.bin 파일의 경로\n","new_model = \"/content/gdrive/MyDrive/kdt_jyg/workspace/Dacon_hansol/practice/Xwena\""],"metadata":{"id":"0MQZVdKtAQVH","executionInfo":{"status":"ok","timestamp":1708677130252,"user_tz":-540,"elapsed":445,"user":{"displayName":"Geass J","userId":"06622059162331348427"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"vCkV5u1L_zuH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708677153643,"user_tz":-540,"elapsed":20972,"user":{"displayName":"Geass J","userId":"06622059162331348427"}},"outputId":"65419e63-ced0-4f99-a8ee-1c0762e39d76"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16\n",")\n","model = PeftModel.from_pretrained(base_model, new_model)\n","\n","\n","model = model.merge_and_unload()\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","\n","# CUDA 사용 가능 여부 확인\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","source":["import torch\n","\n","# 모델을 CPU로 이동\n","model = model.to('cpu')\n","\n","# 모델의 파라미터를 FP32로 변경\n","model = model.float()\n","\n","# 텍스트 입력\n","text = \"유성페인트의 환경 오염에 대한 예시를 알려주세요.\"\n","\n","# 토큰화\n","tokens = tokenizer(text, return_tensors=\"pt\")\n","\n","# 텍스트 생성 설정\n","max_length = 400  # 생성할 텍스트의 최대 길이\n","num_return_sequences = 1  # 생성할 텍스트 시퀀스의 수\n","\n","# 텍스트 생성\n","with torch.no_grad():\n","    generated_ids = model.generate(\n","        tokens[\"input_ids\"],\n","        max_length=max_length,\n","        num_return_sequences=num_return_sequences,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","\n","# 생성된 텍스트 디코딩\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","print(f\"Generated text: {generated_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXpHj7UxFGhz","executionInfo":{"status":"ok","timestamp":1708677806574,"user_tz":-540,"elapsed":184315,"user":{"displayName":"Geass J","userId":"06622059162331348427"}},"outputId":"d61a9b01-ac11-4e84-a966-a075763f829f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated text: 유성페인트의 환경 오염에 대한 예시를 알려주세요.\n","유성페인트는 환경 오염을 일으킬 수 있는 몇 가지 예시가 있습니다.\n","1. 유성페인트의 분해로 인해 대기 중의 유해한 물질이 생성될 수 있습니다. 예를 들어, 유성페인트의 분해로 인해 포름알데히드와 같은 유해 물질이 생성될 수 있습니다.\n","2. 유성페인트는 자연 환경에 해를 끼칠 수 있습니다. 예를 들어, 유성페인트의 분해로 인해 토양과 물이 오염될 수 있습니다. 또한, 유성페인트의 분해로 인해 나무와 같은 식물에도 손상을 줄 수 있습니다.\n","3. 유성페인트는 수질 오염을 일으킬 수 있습니다. 유성페인트의 분해로 인해 물 속에 유해한 물질이 생성될 수 있으며, 이는 수생 생물에게 해를 끼칠 수 있습니다.\n","4. 유성페인트는 건축물의 내구성을 약화시킬 수 있습니다. 유성페인트의 분해로 인해 건축물의 표면에 균열이 생길 수 있으며, 이는 건물의 안전성을 위협할 수 있습니다.\n","5. 유성페인트는 실내 공기 오염을 일으킬 수 있습니다. 유성페인트의 분해로 인해 실내 공기에 유해한 물질이 생성될 수 있으며, 이는 호흡기 질환과 같은 건강 문제를 유발할 수 있습니다.\n","6. 유성페인트는 재활용이 어렵습니다. 유성페인트는 분해되지 않고 그대로 폐기물로 처리되기 때문에 재활용이 어렵습니다.\n","7. 유성페인트는 자연 환경에 대한 부정적인 영향을 최소화하기 위해 친환경적인 대안이 필요합니다. 예를 들어, 유성페인트 대신 친환경적인 페인트를 사용하는 것이 환경 오염을 줄일 수 있습니다.\n"]}]}]}